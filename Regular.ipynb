{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28HwsTdNd13p"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmbGxafud-c4",
        "outputId": "98d26b30-dd7c-42f7-847a-f0b9bef7c355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-01-28T18:56:57.425063Z",
          "iopub.status.busy": "2023-01-28T18:56:57.424201Z",
          "iopub.status.idle": "2023-01-28T18:56:59.210548Z",
          "shell.execute_reply": "2023-01-28T18:56:59.209627Z",
          "shell.execute_reply.started": "2023-01-28T18:56:57.425028Z"
        },
        "id": "wY_blQ12d13s",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqO8cyVqd13v"
      },
      "source": [
        "# **Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-28T18:57:01.242399Z",
          "iopub.status.busy": "2023-01-28T18:57:01.241375Z",
          "iopub.status.idle": "2023-01-28T18:57:01.251362Z",
          "shell.execute_reply": "2023-01-28T18:57:01.250425Z",
          "shell.execute_reply.started": "2023-01-28T18:57:01.242363Z"
        },
        "id": "08KRnSDhd13w",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class VQA_Dataset(Dataset):\n",
        "    def __init__(self, df, vocab, is_test=False, gen_path=''):\n",
        "        self.df = df\n",
        "        self.vocab = vocab\n",
        "        self.is_test = is_test\n",
        "        self.gen_path = gen_path\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        answer = self.df['answer'][idx].split(',')[0]\n",
        "        answer = self.vocab.index(answer)\n",
        "        question = self.df['question'][idx]\n",
        "        path = f\"{self.gen_path}/{self.df['image_id'][idx]}.jpg\"\n",
        "        image = Image.open(path)\n",
        "\n",
        "        if not self.is_test:\n",
        "            return image, question, answer\n",
        "        else:\n",
        "            return image, question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sNT7GqHd13w"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-28T18:57:08.203625Z",
          "iopub.status.busy": "2023-01-28T18:57:08.203267Z",
          "iopub.status.idle": "2023-01-28T18:57:09.478676Z",
          "shell.execute_reply": "2023-01-28T18:57:09.477541Z",
          "shell.execute_reply.started": "2023-01-28T18:57:08.203593Z"
        },
        "id": "1WjyGCyFd13w",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPVisionModel\n",
        "class Visual_Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Visual_Encoder, self).__init__()\n",
        "        self.clip_model = CLIPVisionModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
        "        self.clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
        "\n",
        "    def forward(self, image, device='cuda'):\n",
        "        inputs = self.clip_processor(images=image, return_tensors=\"pt\")\n",
        "        pixel_values = inputs[\"pixel_values\"].to(device)\n",
        "        clip_outputs = self.clip_model(pixel_values=pixel_values)\n",
        "        pooler_output = clip_outputs.pooler_output\n",
        "        return pooler_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-28T18:57:10.601924Z",
          "iopub.status.busy": "2023-01-28T18:57:10.600882Z",
          "iopub.status.idle": "2023-01-28T18:57:10.628971Z",
          "shell.execute_reply": "2023-01-28T18:57:10.628102Z",
          "shell.execute_reply.started": "2023-01-28T18:57:10.601884Z"
        },
        "id": "A258mogMd13x",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, RobertaModel\n",
        "class Text_Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Text_Encoder, self).__init__()\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "        self.roberta_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "    \n",
        "    def forward(self, text, device='cuda'):\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
        "        outputs = self.roberta_model(**inputs.to(device))\n",
        "        pooler_output = outputs.pooler_output\n",
        "        return pooler_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-28T18:57:12.401296Z",
          "iopub.status.busy": "2023-01-28T18:57:12.400915Z",
          "iopub.status.idle": "2023-01-28T18:57:12.409185Z",
          "shell.execute_reply": "2023-01-28T18:57:12.407927Z",
          "shell.execute_reply.started": "2023-01-28T18:57:12.401262Z"
        },
        "id": "aZ_wS62Id13x",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_size=768*2, output_size=582, hidden_size=1024, dropout_prob=0.35):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.fc1 = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        logits = self.fc1(lstm_out)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-28T18:57:14.513991Z",
          "iopub.status.busy": "2023-01-28T18:57:14.513633Z",
          "iopub.status.idle": "2023-01-28T18:57:14.522531Z",
          "shell.execute_reply": "2023-01-28T18:57:14.521549Z",
          "shell.execute_reply.started": "2023-01-28T18:57:14.513959Z"
        },
        "id": "2LuVXnjCd13y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class VQA_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.visual_encoder = Visual_Encoder()\n",
        "        self.textual_encoder = Text_Encoder()\n",
        "        self.classifier = Classifier()\n",
        "    \n",
        "    def forward(self, image, answer, device='cuda'):\n",
        "        text_out = self.textual_encoder(answer).to(device)\n",
        "        image_out = self.visual_encoder(image).to(device)\n",
        "        x = torch.cat((text_out, image_out), dim=1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "    \n",
        "    def freeze(self, visual=True, textual=False, clas=False):\n",
        "        if visual:\n",
        "            for n, p in self.visual_encoder.named_parameters():\n",
        "                p.requires_grad = False\n",
        "        if textual:\n",
        "            for n, p in self.textual_encoder.named_parameters():\n",
        "                p.requires_grad = False\n",
        "        if clas:\n",
        "            for n, p in self.classifier.named_parameters():\n",
        "                p.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOZRz8OBd13y"
      },
      "source": [
        "# **Train/Valid func**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-28T18:57:17.349838Z",
          "iopub.status.busy": "2023-01-28T18:57:17.349469Z",
          "iopub.status.idle": "2023-01-28T18:57:17.357217Z",
          "shell.execute_reply": "2023-01-28T18:57:17.356265Z",
          "shell.execute_reply.started": "2023-01-28T18:57:17.349806Z"
        },
        "id": "YxbpzBxYd13y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_dataloader, optimizer, loss_fn, epoch, device, verbose=False):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    \n",
        "    print(f\"Number of batches: {len(train_dataloader)}\")\n",
        "    prog_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
        "    \n",
        "    for batch, (image, question, answer) in prog_bar:\n",
        "        optimizer.zero_grad()\n",
        "        answer = torch.tensor([answer]).to(device)\n",
        "        preds = model(image, question)\n",
        "        loss = loss_fn(preds, answer)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_item = loss.item()\n",
        "        \n",
        "        if batch >= 129:\n",
        "            break\n",
        "        \n",
        "        running_loss += loss_item\n",
        "        prog_bar.set_description(f\"loss: {loss_item:.4f}\")\n",
        "        \n",
        "        if verbose and batch % 20 == 0:\n",
        "            print(f\"Batch: {batch}, Loss: {loss_item}\")\n",
        "    \n",
        "    avg_loss = running_loss / min(len(train_dataloader), 30)\n",
        "    \n",
        "    return avg_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-28T18:57:18.812252Z",
          "iopub.status.busy": "2023-01-28T18:57:18.811329Z",
          "iopub.status.idle": "2023-01-28T18:57:18.819925Z",
          "shell.execute_reply": "2023-01-28T18:57:18.818822Z",
          "shell.execute_reply.started": "2023-01-28T18:57:18.812213Z"
        },
        "id": "euV4zYRkd13z",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model, valid_dataloader, loss_fn, epoch, device, log_wandb=True, verbose=False):\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    prog_bar = tqdm(enumerate(valid_dataloader), total=len(valid_dataloader))\n",
        "    for batch, (image, quetion, answer) in prog_bar:\n",
        "        answer = torch.tensor([answer]).to(device)\n",
        "        preds = model(image,quetion)\n",
        "        loss = loss_fn(preds, answer)\n",
        "        \n",
        "        loss_item = loss.item()\n",
        "        running_loss += loss_item\n",
        "        \n",
        "        prog_bar.set_description(f\"val_loss: {loss_item:.4f}\")        \n",
        "        if verbose == True and batch % 10 == 0:\n",
        "            print(f\"Batch: {batch}, Loss: {loss_item}\")\n",
        "        \n",
        "        # stop iterating if we have reached the end of the test set\n",
        "        if batch >= 10:\n",
        "            break\n",
        "    \n",
        "    avg_val_loss = running_loss / len(valid_dataloader)\n",
        "    \n",
        "    return avg_val_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zezCJ4Yd13z"
      },
      "source": [
        "# **Main**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-01-28T18:57:21.085402Z",
          "iopub.status.busy": "2023-01-28T18:57:21.083058Z",
          "iopub.status.idle": "2023-01-28T18:57:21.139027Z",
          "shell.execute_reply": "2023-01-28T18:57:21.138125Z",
          "shell.execute_reply.started": "2023-01-28T18:57:21.085353Z"
        },
        "id": "Cr0DCzPFd130",
        "outputId": "2184be86-f5fe-45e4-8131-836413deaac6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv('./data_train.csv')\n",
        "test_df = pd.read_csv('./data_eval.csv')\n",
        "\n",
        "# Set the path to the images directory\n",
        "gen_path = 'path/to/Final'\n",
        "\n",
        "# Read the vocabulary file\n",
        "with open('./answer_space.txt') as f:\n",
        "    vocab = f.read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-28T18:57:23.409189Z",
          "iopub.status.busy": "2023-01-28T18:57:23.4088Z",
          "iopub.status.idle": "2023-01-28T18:57:23.41411Z",
          "shell.execute_reply": "2023-01-28T18:57:23.413157Z",
          "shell.execute_reply.started": "2023-01-28T18:57:23.409154Z"
        },
        "id": "s7XJ6VzRd130",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "trainset = VQA_Dataset(train_df,vocab,gen_path=gen_path)\n",
        "testset = VQA_Dataset(test_df,vocab,gen_path=gen_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2023-01-28T18:57:24.751713Z",
          "iopub.status.busy": "2023-01-28T18:57:24.75135Z",
          "iopub.status.idle": "2023-01-28T19:00:57.70953Z",
          "shell.execute_reply": "2023-01-28T19:00:57.708528Z",
          "shell.execute_reply.started": "2023-01-28T18:57:24.751681Z"
        },
        "id": "erxPQVN9d130",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "d990b963-dbcd-47ac-b98d-f520eb872e23",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at openai/clip-vit-base-patch16 were not used when initializing CLIPVisionModel: ['text_model.encoder.layers.7.self_attn.k_proj.bias', 'text_model.encoder.layers.6.self_attn.v_proj.bias', 'text_model.encoder.layers.0.self_attn.q_proj.bias', 'text_model.encoder.layers.11.self_attn.k_proj.bias', 'text_model.encoder.layers.6.self_attn.out_proj.weight', 'text_model.encoder.layers.2.self_attn.v_proj.bias', 'text_model.encoder.layers.4.self_attn.q_proj.weight', 'text_model.encoder.layers.11.self_attn.v_proj.bias', 'text_model.encoder.layers.7.self_attn.v_proj.weight', 'text_model.encoder.layers.1.mlp.fc1.bias', 'text_model.encoder.layers.7.self_attn.k_proj.weight', 'text_model.encoder.layers.9.mlp.fc2.bias', 'text_model.encoder.layers.11.self_attn.q_proj.weight', 'text_model.encoder.layers.3.self_attn.q_proj.bias', 'text_model.encoder.layers.1.self_attn.k_proj.weight', 'text_model.encoder.layers.9.layer_norm1.weight', 'text_model.encoder.layers.1.self_attn.v_proj.bias', 'text_model.encoder.layers.10.self_attn.q_proj.weight', 'text_model.encoder.layers.0.mlp.fc1.weight', 'text_model.encoder.layers.2.mlp.fc1.weight', 'text_model.encoder.layers.4.self_attn.out_proj.weight', 'text_model.encoder.layers.8.layer_norm2.bias', 'text_model.encoder.layers.2.self_attn.q_proj.weight', 'text_model.encoder.layers.5.layer_norm2.bias', 'text_model.encoder.layers.0.layer_norm1.bias', 'text_model.encoder.layers.4.mlp.fc1.weight', 'text_model.encoder.layers.2.self_attn.k_proj.weight', 'text_model.encoder.layers.0.layer_norm1.weight', 'text_model.encoder.layers.0.mlp.fc2.bias', 'text_model.encoder.layers.0.self_attn.q_proj.weight', 'text_model.encoder.layers.10.layer_norm2.bias', 'text_model.encoder.layers.3.self_attn.v_proj.weight', 'text_model.encoder.layers.8.self_attn.k_proj.weight', 'text_model.encoder.layers.1.mlp.fc2.bias', 'text_model.encoder.layers.10.mlp.fc1.bias', 'text_model.encoder.layers.5.self_attn.k_proj.bias', 'text_model.encoder.layers.8.self_attn.v_proj.weight', 'text_model.encoder.layers.5.self_attn.q_proj.weight', 'text_model.encoder.layers.11.mlp.fc2.weight', 'text_model.encoder.layers.0.self_attn.v_proj.weight', 'text_model.encoder.layers.7.layer_norm1.bias', 'text_model.encoder.layers.4.mlp.fc1.bias', 'text_model.encoder.layers.4.layer_norm1.bias', 'text_model.encoder.layers.9.self_attn.v_proj.bias', 'text_model.encoder.layers.4.layer_norm1.weight', 'text_model.encoder.layers.3.layer_norm2.weight', 'text_model.encoder.layers.10.self_attn.out_proj.weight', 'text_model.encoder.layers.7.layer_norm1.weight', 'text_model.encoder.layers.11.layer_norm1.weight', 'text_model.encoder.layers.9.self_attn.q_proj.weight', 'text_model.encoder.layers.2.layer_norm2.bias', 'text_model.encoder.layers.6.self_attn.v_proj.weight', 'text_model.encoder.layers.10.self_attn.v_proj.bias', 'text_model.encoder.layers.2.self_attn.v_proj.weight', 'text_model.encoder.layers.7.mlp.fc2.weight', 'text_model.encoder.layers.0.self_attn.k_proj.weight', 'logit_scale', 'text_model.encoder.layers.3.layer_norm1.weight', 'text_model.encoder.layers.2.self_attn.out_proj.weight', 'text_model.encoder.layers.7.mlp.fc2.bias', 'text_model.encoder.layers.2.layer_norm1.weight', 'text_model.encoder.layers.4.mlp.fc2.bias', 'text_model.encoder.layers.8.self_attn.out_proj.bias', 'text_model.encoder.layers.9.self_attn.k_proj.bias', 'text_model.encoder.layers.8.self_attn.out_proj.weight', 'text_model.encoder.layers.4.self_attn.out_proj.bias', 'text_model.encoder.layers.6.layer_norm1.weight', 'text_model.encoder.layers.10.self_attn.v_proj.weight', 'text_model.encoder.layers.3.layer_norm2.bias', 'text_model.encoder.layers.9.self_attn.k_proj.weight', 'text_model.encoder.layers.5.layer_norm1.weight', 'text_model.encoder.layers.6.self_attn.q_proj.weight', 'text_model.encoder.layers.3.mlp.fc2.bias', 'text_model.encoder.layers.5.mlp.fc1.weight', 'text_model.encoder.layers.1.layer_norm1.bias', 'text_model.encoder.layers.7.self_attn.q_proj.weight', 'text_model.encoder.layers.11.self_attn.out_proj.bias', 'text_model.encoder.layers.7.mlp.fc1.weight', 'text_model.encoder.layers.8.mlp.fc2.weight', 'text_model.encoder.layers.7.self_attn.out_proj.bias', 'text_model.encoder.layers.10.self_attn.k_proj.bias', 'text_model.encoder.layers.0.self_attn.v_proj.bias', 'text_model.encoder.layers.2.mlp.fc2.weight', 'text_model.encoder.layers.6.layer_norm2.bias', 'text_model.encoder.layers.9.mlp.fc1.weight', 'text_model.encoder.layers.1.layer_norm2.bias', 'text_model.encoder.layers.7.mlp.fc1.bias', 'text_model.encoder.layers.9.mlp.fc2.weight', 'text_model.embeddings.position_ids', 'text_model.encoder.layers.10.self_attn.q_proj.bias', 'text_model.encoder.layers.9.self_attn.out_proj.bias', 'text_model.encoder.layers.1.self_attn.v_proj.weight', 'text_model.encoder.layers.11.layer_norm1.bias', 'text_model.encoder.layers.9.self_attn.out_proj.weight', 'text_model.encoder.layers.3.mlp.fc1.bias', 'text_model.encoder.layers.5.self_attn.k_proj.weight', 'text_model.encoder.layers.6.mlp.fc2.bias', 'text_model.encoder.layers.4.self_attn.q_proj.bias', 'text_model.encoder.layers.10.layer_norm1.bias', 'text_model.final_layer_norm.weight', 'text_model.encoder.layers.10.mlp.fc1.weight', 'text_model.encoder.layers.1.layer_norm1.weight', 'text_model.encoder.layers.0.self_attn.out_proj.bias', 'text_model.encoder.layers.4.layer_norm2.bias', 'text_model.encoder.layers.11.self_attn.q_proj.bias', 'text_model.encoder.layers.2.self_attn.out_proj.bias', 'text_model.encoder.layers.8.self_attn.q_proj.weight', 'text_model.encoder.layers.2.layer_norm1.bias', 'text_model.encoder.layers.1.self_attn.k_proj.bias', 'text_model.encoder.layers.8.self_attn.q_proj.bias', 'text_model.embeddings.position_embedding.weight', 'text_model.encoder.layers.11.layer_norm2.bias', 'text_model.encoder.layers.6.self_attn.q_proj.bias', 'text_model.encoder.layers.8.layer_norm1.weight', 'text_model.encoder.layers.1.mlp.fc1.weight', 'text_model.encoder.layers.9.mlp.fc1.bias', 'text_model.encoder.layers.2.self_attn.q_proj.bias', 'text_model.encoder.layers.9.self_attn.v_proj.weight', 'text_model.encoder.layers.6.self_attn.k_proj.bias', 'text_model.encoder.layers.4.self_attn.v_proj.bias', 'text_model.encoder.layers.10.layer_norm2.weight', 'text_model.encoder.layers.5.self_attn.out_proj.weight', 'text_model.encoder.layers.11.mlp.fc1.weight', 'text_model.encoder.layers.3.self_attn.out_proj.weight', 'text_model.encoder.layers.9.layer_norm2.weight', 'text_model.encoder.layers.11.mlp.fc1.bias', 'text_model.encoder.layers.5.self_attn.out_proj.bias', 'text_model.encoder.layers.4.mlp.fc2.weight', 'text_model.encoder.layers.4.layer_norm2.weight', 'text_model.encoder.layers.8.layer_norm1.bias', 'text_model.encoder.layers.10.self_attn.k_proj.weight', 'text_model.encoder.layers.5.layer_norm1.bias', 'text_model.encoder.layers.4.self_attn.k_proj.bias', 'text_model.encoder.layers.5.self_attn.v_proj.bias', 'text_model.encoder.layers.8.mlp.fc1.bias', 'text_model.encoder.layers.6.layer_norm2.weight', 'visual_projection.weight', 'text_model.encoder.layers.9.layer_norm2.bias', 'text_model.encoder.layers.8.mlp.fc1.weight', 'text_model.encoder.layers.7.self_attn.q_proj.bias', 'text_model.encoder.layers.11.layer_norm2.weight', 'text_model.encoder.layers.8.layer_norm2.weight', 'text_model.encoder.layers.5.layer_norm2.weight', 'text_model.encoder.layers.8.self_attn.k_proj.bias', 'text_model.encoder.layers.3.self_attn.out_proj.bias', 'text_model.encoder.layers.5.mlp.fc2.bias', 'text_model.encoder.layers.1.self_attn.out_proj.weight', 'text_model.encoder.layers.1.self_attn.q_proj.bias', 'text_model.embeddings.token_embedding.weight', 'text_model.encoder.layers.3.self_attn.q_proj.weight', 'text_model.encoder.layers.3.self_attn.k_proj.bias', 'text_model.encoder.layers.11.self_attn.out_proj.weight', 'text_model.encoder.layers.0.mlp.fc1.bias', 'text_model.encoder.layers.5.self_attn.v_proj.weight', 'text_model.encoder.layers.1.self_attn.q_proj.weight', 'text_model.encoder.layers.2.layer_norm2.weight', 'text_model.encoder.layers.5.mlp.fc1.bias', 'text_model.encoder.layers.11.mlp.fc2.bias', 'text_model.encoder.layers.7.layer_norm2.bias', 'text_model.encoder.layers.7.layer_norm2.weight', 'text_model.encoder.layers.3.self_attn.k_proj.weight', 'text_model.encoder.layers.3.self_attn.v_proj.bias', 'text_model.encoder.layers.1.self_attn.out_proj.bias', 'text_model.final_layer_norm.bias', 'text_model.encoder.layers.0.mlp.fc2.weight', 'text_model.encoder.layers.10.mlp.fc2.weight', 'text_model.encoder.layers.10.layer_norm1.weight', 'text_model.encoder.layers.2.self_attn.k_proj.bias', 'text_model.encoder.layers.7.self_attn.v_proj.bias', 'text_model.encoder.layers.5.mlp.fc2.weight', 'text_model.encoder.layers.6.mlp.fc1.weight', 'text_model.encoder.layers.6.self_attn.out_proj.bias', 'text_model.encoder.layers.4.self_attn.v_proj.weight', 'text_model.encoder.layers.0.self_attn.k_proj.bias', 'text_model.encoder.layers.3.layer_norm1.bias', 'text_model.encoder.layers.3.mlp.fc2.weight', 'text_projection.weight', 'text_model.encoder.layers.6.self_attn.k_proj.weight', 'text_model.encoder.layers.7.self_attn.out_proj.weight', 'text_model.encoder.layers.8.mlp.fc2.bias', 'text_model.encoder.layers.4.self_attn.k_proj.weight', 'text_model.encoder.layers.6.mlp.fc2.weight', 'text_model.encoder.layers.10.mlp.fc2.bias', 'text_model.encoder.layers.0.self_attn.out_proj.weight', 'text_model.encoder.layers.11.self_attn.k_proj.weight', 'text_model.encoder.layers.6.layer_norm1.bias', 'text_model.encoder.layers.10.self_attn.out_proj.bias', 'text_model.encoder.layers.2.mlp.fc1.bias', 'text_model.encoder.layers.1.layer_norm2.weight', 'text_model.encoder.layers.5.self_attn.q_proj.bias', 'text_model.encoder.layers.3.mlp.fc1.weight', 'text_model.encoder.layers.8.self_attn.v_proj.bias', 'text_model.encoder.layers.9.self_attn.q_proj.bias', 'text_model.encoder.layers.6.mlp.fc1.bias', 'text_model.encoder.layers.0.layer_norm2.bias', 'text_model.encoder.layers.9.layer_norm1.bias', 'text_model.encoder.layers.2.mlp.fc2.bias', 'text_model.encoder.layers.0.layer_norm2.weight', 'text_model.encoder.layers.1.mlp.fc2.weight', 'text_model.encoder.layers.11.self_attn.v_proj.weight']\n",
            "- This IS expected if you are initializing CLIPVisionModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPVisionModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model = VQA_Model()\n",
        "model = model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-01-28T19:01:04.515777Z",
          "iopub.status.busy": "2023-01-28T19:01:04.515413Z",
          "iopub.status.idle": "2023-01-28T19:01:08.461749Z",
          "shell.execute_reply": "2023-01-28T19:01:08.459764Z",
          "shell.execute_reply.started": "2023-01-28T19:01:04.515748Z"
        },
        "id": "v_Zp8mMbd131",
        "outputId": "d6c1982f-5860-4465-e427-2446a9c8c266",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = transformers.AdamW(model.parameters(),lr=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-28T16:47:26.601139Z",
          "iopub.status.busy": "2023-01-28T16:47:26.600435Z",
          "iopub.status.idle": "2023-01-28T16:47:26.607538Z",
          "shell.execute_reply": "2023-01-28T16:47:26.606537Z",
          "shell.execute_reply.started": "2023-01-28T16:47:26.601102Z"
        },
        "id": "NGurNcC5d131",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.freeze(visual=True,textual=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-01-28T19:01:19.215719Z",
          "iopub.status.busy": "2023-01-28T19:01:19.215023Z",
          "iopub.status.idle": "2023-01-28T20:36:35.035286Z",
          "shell.execute_reply": "2023-01-28T20:36:35.033817Z",
          "shell.execute_reply.started": "2023-01-28T19:01:19.215679Z"
        },
        "id": "sZP7v0Fdd132",
        "outputId": "e3ff5a66-a5c3-4c59-a391-0b71f633d256",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 6.4595:  99%|█████████▉| 129/130 [00:28<00:00,  4.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 27.230798625946044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 6.1053:  91%|█████████ | 10/11 [00:01<00:00,  5.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 6.152606443925337\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 6.1862:  99%|█████████▉| 129/130 [00:17<00:00,  7.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 26.49994799296061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 5.9021:  91%|█████████ | 10/11 [00:01<00:00,  7.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 5.905248988758434\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 5.9839:  99%|█████████▉| 129/130 [00:17<00:00,  7.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 25.567242495218913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 5.6014:  91%|█████████ | 10/11 [00:02<00:00,  4.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 5.562411698428067\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 5.8147:  99%|█████████▉| 129/130 [00:17<00:00,  7.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 24.191878652572633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 5.1869:  91%|█████████ | 10/11 [00:01<00:00,  7.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 5.105645699934526\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 5.2681:  99%|█████████▉| 129/130 [00:17<00:00,  7.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 22.514169001579283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 4.7153:  91%|█████████ | 10/11 [00:01<00:00,  5.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 4.5740460699254815\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 4.9797:  99%|█████████▉| 129/130 [00:17<00:00,  7.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 20.62461661497752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 4.2737:  91%|█████████ | 10/11 [00:01<00:00,  7.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 4.067878398028287\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 4.5955:  99%|█████████▉| 129/130 [00:17<00:00,  7.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 18.982038990656534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.9514:  91%|█████████ | 10/11 [00:01<00:00,  7.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 3.6897918527776543\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 4.1186:  99%|█████████▉| 129/130 [00:17<00:00,  7.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 17.94798128604889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.7359:  91%|█████████ | 10/11 [00:01<00:00,  7.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 3.4509987180883233\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 4.2976:  99%|█████████▉| 129/130 [00:17<00:00,  7.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 17.17803544998169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.6183:  91%|█████████ | 10/11 [00:01<00:00,  7.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 3.3052017472007056\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 4.0449:  99%|█████████▉| 129/130 [00:17<00:00,  7.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 16.91317607561747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.5541:  91%|█████████ | 10/11 [00:01<00:00,  7.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 3.210336370901628\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 3.9040:  99%|█████████▉| 129/130 [00:17<00:00,  7.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 16.400334417819977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.4964:  91%|█████████ | 10/11 [00:01<00:00,  7.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 3.143911209973422\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 3.8081:  99%|█████████▉| 129/130 [00:18<00:00,  7.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 16.217218232154845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.4614:  91%|█████████ | 10/11 [00:01<00:00,  7.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 3.091057235544378\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 3.2504:  99%|█████████▉| 129/130 [00:17<00:00,  7.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 15.978131858507792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.4468:  91%|█████████ | 10/11 [00:01<00:00,  7.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 3.0472665374929253\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 3.4634:  99%|█████████▉| 129/130 [00:18<00:00,  6.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 15.543312366803487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.4250:  91%|█████████ | 10/11 [00:01<00:00,  6.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 3.015853426673196\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 3.2922:  99%|█████████▉| 129/130 [00:17<00:00,  7.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 15.684847176074982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.4086:  91%|█████████ | 10/11 [00:01<00:00,  7.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 2.9888033216649834\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 3.2175:  99%|█████████▉| 129/130 [00:17<00:00,  7.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 15.345218996206919\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.4054:  91%|█████████ | 10/11 [00:01<00:00,  5.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 2.965437889099121\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 3.1501:  99%|█████████▉| 129/130 [00:17<00:00,  7.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 15.29057796796163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.3749:  91%|█████████ | 10/11 [00:01<00:00,  7.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 2.939955061132258\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 2.9031:  99%|█████████▉| 129/130 [00:18<00:00,  7.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 15.133690937360127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.3597:  91%|█████████ | 10/11 [00:01<00:00,  5.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 2.9183449203317817\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 2.8743:  99%|█████████▉| 129/130 [00:18<00:00,  7.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 14.98233227332433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.3572:  91%|█████████ | 10/11 [00:01<00:00,  6.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 2.903102094476873\n",
            "Number of batches: 130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss: 2.7423:  99%|█████████▉| 129/130 [00:18<00:00,  6.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss - 14.881067125002543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.3516:  91%|█████████ | 10/11 [00:01<00:00,  5.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_loss - 2.8879667737267236\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(10):\n",
        "    train_loss = train_one_epoch(model, trainset, optimizer, criterion, epoch=1, device='cuda')\n",
        "    print(f'train_loss - {train_loss}')\n",
        "    valid_loss = valid_one_epoch(model, testset, criterion, epoch=1, device='cuda')\n",
        "    print(f'valid_loss - {valid_loss}')\n",
        "    torch.save(model.state_dict(), './my_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-01-28T18:56:47.520204Z",
          "iopub.status.busy": "2023-01-28T18:56:47.51985Z",
          "iopub.status.idle": "2023-01-28T18:56:47.598501Z",
          "shell.execute_reply": "2023-01-28T18:56:47.597062Z",
          "shell.execute_reply.started": "2023-01-28T18:56:47.520131Z"
        },
        "id": "PveydwY9d132",
        "outputId": "835ecbb3-0c27-4853-b1ef-962017eef7ef",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val_loss: 3.3516:  91%|█████████ | 10/11 [00:01<00:00,  8.41it/s]\n"
          ]
        }
      ],
      "source": [
        "valid_loss = valid_one_epoch(model, testset, criterion, epoch=10, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-01-28T16:38:45.143642Z",
          "iopub.status.busy": "2023-01-28T16:38:45.143243Z",
          "iopub.status.idle": "2023-01-28T16:38:45.150613Z",
          "shell.execute_reply": "2023-01-28T16:38:45.149675Z",
          "shell.execute_reply.started": "2023-01-28T16:38:45.143607Z"
        },
        "id": "H_wlJb4nd132",
        "outputId": "90d4eae2-94a9-4f47-90b0-696a878c6bd9",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.8879667737267236"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-01-28T20:48:33.808642Z",
          "iopub.status.busy": "2023-01-28T20:48:33.807965Z",
          "iopub.status.idle": "2023-01-28T20:50:00.900246Z",
          "shell.execute_reply": "2023-01-28T20:50:00.898597Z",
          "shell.execute_reply.started": "2023-01-28T20:48:33.808607Z"
        },
        "id": "6yS5fgFRd133",
        "outputId": "65ff7136-4bd5-4ff5-9261-fc85f0b6e3c1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 10/11 [00:01<00:00,  9.93it/s]\n"
          ]
        }
      ],
      "source": [
        "preds = []\n",
        "gt = []\n",
        "prog_bar = tqdm(enumerate(testset), total=len(testset))\n",
        "for batch, (image,quetion,answer) in prog_bar:\n",
        "    if batch >= 10:\n",
        "        break\n",
        "    answer = torch.tensor([answer]).to('cuda')\n",
        "    gt += [answer]\n",
        "    preds += [model(image,quetion).argmax(dim=-1).to('cpu').flatten().numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "YsNd7prdmnEW"
      },
      "outputs": [],
      "source": [
        "ggt = []\n",
        "for i in gt:\n",
        "    ggt += i.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce4cQXeFmqS9",
        "outputId": "72892c3d-0b5e-48c6-f90f-c259dd1762dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[12, 22, 12, 4, 0, 43, 24, 8, 25, 4]"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ggt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "fgPqdmwgmtdR"
      },
      "outputs": [],
      "source": [
        "pp = []\n",
        "for i in preds:\n",
        "    pp += list(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2023-01-28T15:17:16.263367Z",
          "iopub.status.busy": "2023-01-28T15:17:16.262782Z",
          "iopub.status.idle": "2023-01-28T15:17:16.287519Z",
          "shell.execute_reply": "2023-01-28T15:17:16.286503Z",
          "shell.execute_reply.started": "2023-01-28T15:17:16.263329Z"
        },
        "id": "ouqLOfk5d134",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "005490ae-2ef1-4a17-83a6-f977cee87c17",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[22, 22, 22, 4, 4, 4, 4, 4, 4, 4]"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-01-28T20:50:57.683026Z",
          "iopub.status.busy": "2023-01-28T20:50:57.682656Z",
          "iopub.status.idle": "2023-01-28T20:50:57.701435Z",
          "shell.execute_reply": "2023-01-28T20:50:57.700437Z",
          "shell.execute_reply.started": "2023-01-28T20:50:57.682993Z"
        },
        "id": "zPI9BYpjd134",
        "outputId": "8801158c-ee57-43da-e5ee-2acb2f0ff206",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.1388888888888889, 0.3)"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "f1_score(ggt, pp, average='weighted'), accuracy_score(ggt,pp)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
